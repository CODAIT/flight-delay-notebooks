{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025967,
     "end_time": "2020-11-18T10:43:33.258513",
     "exception": false,
     "start_time": "2020-11-18T10:43:33.232546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Deploying the Flight Delay Model\n",
    "\n",
    "In this notebook, we deploy the model we trained to predict flight delays, using [Kubeflow Serving](https://www.kubeflow.org/docs/components/serving/kfserving/).\n",
    "\n",
    "**Note** this notebook requires access to a KFServing installation. See the [KFServing instructions](../kfserving.md) for details. If running the pipeline on the Kubeflow Pipelines runtime, also see the [readme instructions](../README.md) for the link to install KFP.\n",
    "\n",
    "#### Import required modules\n",
    "\n",
    "Import and configure the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.508485,
     "end_time": "2020-11-18T10:43:35.791832",
     "exception": false,
     "start_time": "2020-11-18T10:43:33.283347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -q kfserving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.43359,
     "end_time": "2020-11-18T10:43:36.243027",
     "exception": false,
     "start_time": "2020-11-18T10:43:35.809437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "# minio is part of kfserving \n",
    "from minio import Minio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018201,
     "end_time": "2020-11-18T10:43:36.277908",
     "exception": false,
     "start_time": "2020-11-18T10:43:36.259707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Upload the model to object storage\n",
    "\n",
    "Our notebook has access to the trained model file, which was exported by the previous pipeline phase. _However_, when using a Kubeflow Pipelines runtime, it is not possible to programatically access the object storage bucket. It also makes execution mechanics different between local and KFP execution mode.\n",
    "\n",
    "So, here we will use a dedicated bucket for models in object storage, and upload it from the notebook execution environment. We will then deploy the KFServing inference service using that object storage location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.064235,
     "end_time": "2020-11-18T10:43:36.364959",
     "exception": false,
     "start_time": "2020-11-18T10:43:36.300724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up the minio client to access object storage buckets\n",
    "os_url = os.environ.get('OS_URL', 'minio-service:9000')\n",
    "access_key = os.environ.get('ACCESS_KEY_ID', 'minio')\n",
    "secret_key = os.environ.get('SECRET_ACCESS_KEY', 'minio123')\n",
    "\n",
    "mc = Minio(os_url,\n",
    "           access_key=access_key,\n",
    "           secret_key=secret_key,\n",
    "           secure=False)\n",
    "\n",
    "print('Current buckets:')\n",
    "for b in mc.list_buckets():\n",
    "    print('  ' + b.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.090772,
     "end_time": "2020-11-18T10:43:36.476952",
     "exception": false,
     "start_time": "2020-11-18T10:43:36.386180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a bucket to upload the model file to\n",
    "# NOTE we delete any existing model file and re-create the bucket\n",
    "model_bucket = os.environ.get('MODEL_BUCKET', 'models')\n",
    "model_dir = os.environ.get('MODEL_DIR', 'models')\n",
    "model_file = 'model.joblib'\n",
    "model_path = '{}/{}'.format(model_dir, model_file)\n",
    "\n",
    "mc.remove_object(model_bucket, model_file)\n",
    "mc.remove_bucket(model_bucket)\n",
    "mc.make_bucket(model_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.091737,
     "end_time": "2020-11-18T10:43:36.585366",
     "exception": false,
     "start_time": "2020-11-18T10:43:36.493629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# upload the model file\n",
    "file_stat = os.stat(model_path)\n",
    "with open(model_path, 'rb') as data:\n",
    "    mc.put_object(model_bucket, model_file, data, file_stat.st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.051157,
     "end_time": "2020-11-18T10:43:36.668293",
     "exception": false,
     "start_time": "2020-11-18T10:43:36.617136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check whether the model file is there\n",
    "for o in mc.list_objects('models'):\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027185,
     "end_time": "2020-11-18T10:43:36.728680",
     "exception": false,
     "start_time": "2020-11-18T10:43:36.701495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create the inference service\n",
    "\n",
    "Next, we use the KFServing Python client to create the inference service.\n",
    "\n",
    "**Note** the prerequisites (see the [KF Serving instructions](../kfserving.md)):\n",
    "1. A service account and related secret for the object storage service\n",
    "1. Specify the custom `sklearnserver` Docker image\n",
    "1. Patch the KFP `pipeline-runner` service account role to allow creating a KFServing `inferenceservice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.416047,
     "end_time": "2020-11-18T10:43:38.168483",
     "exception": false,
     "start_time": "2020-11-18T10:43:36.752436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kubernetes import client\n",
    "\n",
    "from kfserving import KFServingClient\n",
    "from kfserving import constants\n",
    "from kfserving import utils\n",
    "from kfserving import V1alpha2EndpointSpec\n",
    "from kfserving import V1alpha2PredictorSpec\n",
    "from kfserving import V1alpha2SKLearnSpec\n",
    "from kfserving import V1alpha2InferenceServiceSpec\n",
    "from kfserving import V1alpha2InferenceService\n",
    "from kubernetes.client import V1ResourceRequirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.054934,
     "end_time": "2020-11-18T10:43:38.236678",
     "exception": false,
     "start_time": "2020-11-18T10:43:38.181744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "KFServing = KFServingClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.020742,
     "end_time": "2020-11-18T10:43:38.274446",
     "exception": false,
     "start_time": "2020-11-18T10:43:38.253704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we need to use the 'kubeflow' namespace so that the KFP runner can create the inference service\n",
    "namespace = 'kubeflow'\n",
    "# this is the service account created for S3 access credentials\n",
    "service_acc = 'kfserving-sa'\n",
    "model_storage_uri = 's3://{}'.format(model_bucket)\n",
    "model_name = 'flight-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.081928,
     "end_time": "2020-11-18T10:43:38.371471",
     "exception": false,
     "start_time": "2020-11-18T10:43:38.289543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_version = constants.KFSERVING_GROUP + '/' + constants.KFSERVING_VERSION\n",
    "default_endpoint_spec = V1alpha2EndpointSpec(\n",
    "    predictor=V1alpha2PredictorSpec(\n",
    "        sklearn=V1alpha2SKLearnSpec(\n",
    "            storage_uri=model_storage_uri,\n",
    "            resources=V1ResourceRequirements(\n",
    "                requests={'cpu':'100m','memory':'1Gi'},\n",
    "                limits={'cpu':'100m', 'memory':'1Gi'}\n",
    "            )\n",
    "        ),\n",
    "        service_account_name=service_acc\n",
    "    )\n",
    ")\n",
    "    \n",
    "isvc = V1alpha2InferenceService(api_version=api_version,\n",
    "                                kind=constants.KFSERVING_KIND,\n",
    "                                metadata=client.V1ObjectMeta(\n",
    "                                    name=model_name, namespace=namespace),\n",
    "                                spec=V1alpha2InferenceServiceSpec(default=default_endpoint_spec))\n",
    "KFServing.create(isvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 37.677419,
     "end_time": "2020-11-18T10:44:16.062539",
     "exception": false,
     "start_time": "2020-11-18T10:43:38.385120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wait for the inference service to be ready\n",
    "KFServing.get(model_name, namespace=namespace, watch=True, timeout_seconds=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027246,
     "end_time": "2020-11-18T10:44:16.106332",
     "exception": false,
     "start_time": "2020-11-18T10:44:16.079086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Test the inference service\n",
    "\n",
    "Once the inference service is running and available, we can send some test data to the service.\n",
    "\n",
    "**Note** that when deployed into KFP, we need to use the cluster-local url for the model. When executing locally, we assume that port-forwarding is enabled to allow access to the ingress gateway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.073183,
     "end_time": "2020-11-18T10:44:16.218240",
     "exception": false,
     "start_time": "2020-11-18T10:44:16.145057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "service = KFServing.get(model_name, namespace=namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.053377,
     "end_time": "2020-11-18T10:44:16.311743",
     "exception": false,
     "start_time": "2020-11-18T10:44:16.258366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the 10 example rows from our test data, and display a few rows\n",
    "examples = np.load('data/test_rows.npy')\n",
    "examples[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.10901,
     "end_time": "2020-11-18T10:44:16.453511",
     "exception": false,
     "start_time": "2020-11-18T10:44:16.344501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_mode = os.environ.get('MODEL_MODE', 'local')\n",
    "model_data = {\"instances\": examples.tolist()}\n",
    "if model_mode == 'local':\n",
    "    # executing locally, use the ingress gateway (we assume port-forwarding) \n",
    "    url = f'http://localhost:8080/v1/models/{model_name}:predict'\n",
    "    service_hostname = '{}.{}.example.com'.format(model_name, namespace)\n",
    "    headers = {'Host': service_hostname}\n",
    "    resp = requests.post(url=url, json=model_data, headers=headers)\n",
    "else:\n",
    "    # we are executing in KFP, use the cluster-local address\n",
    "    url = service['status']['address']['url']\n",
    "    resp = requests.post(url=url, json=model_data)\n",
    "\n",
    "resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024178,
     "end_time": "2020-11-18T10:44:16.496689",
     "exception": false,
     "start_time": "2020-11-18T10:44:16.472511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Delete the model service\n",
    "\n",
    "Once we are done, we clean up the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.066867,
     "end_time": "2020-11-18T10:44:16.588227",
     "exception": false,
     "start_time": "2020-11-18T10:44:16.521360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "KFServing.delete(model_name, namespace=namespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039548,
     "end_time": "2020-11-18T10:44:16.674807",
     "exception": false,
     "start_time": "2020-11-18T10:44:16.635259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Authors\n",
    "This notebook was created by the [Center for Open-Source Data & AI Technologies](http://codait.org).\n",
    "\n",
    "Copyright © 2019 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "duration": 46.096598,
   "end_time": "2020-11-18T10:44:18.108854",
   "environment_variables": {},
   "exception": null,
   "input_path": "/Users/nick/workspace/python/flight-delay-notebooks/notebooks/deploy_model.ipynb",
   "output_path": "/Users/nick/workspace/python/flight-delay-notebooks/notebooks/deploy_model.ipynb",
   "parameters": {},
   "start_time": "2020-11-18T10:43:32.012256",
   "version": "2.1.1"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
