{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026827,
     "end_time": "2020-11-18T10:43:10.843474",
     "exception": false,
     "start_time": "2020-11-18T10:43:10.816647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predicting Flight Delays\n",
    "\n",
    "In this notebook, we use the combined flight delay and weather data we have created to create and evaluate models to predict flight delays.\n",
    "\n",
    "**Note** the full flight delay dataset is very large (over 80GB uncompressed), so we are working with a smaller sample dataset. Hence our results may not be a true reflection of the results on the full dataset.\n",
    "\n",
    "#### Import required modules\n",
    "\n",
    "Import and configure the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 3.113441,
     "end_time": "2020-11-18T10:43:13.981561",
     "exception": false,
     "start_time": "2020-11-18T10:43:10.868120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install seaborn scikit-learn > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.755517,
     "end_time": "2020-11-18T10:43:15.772084",
     "exception": false,
     "start_time": "2020-11-18T10:43:14.016567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define required imports\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style='darkgrid', palette='deep')\n",
    "# These set pandas max column and row display in the notebook\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.053132,
     "end_time": "2020-11-18T10:43:15.854310",
     "exception": false,
     "start_time": "2020-11-18T10:43:15.801178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_EXPORT_FOLDER = 'models'\n",
    "from pathlib import Path\n",
    "export_path = Path(MODEL_EXPORT_FOLDER)\n",
    "export_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027723,
     "end_time": "2020-11-18T10:43:15.907403",
     "exception": false,
     "start_time": "2020-11-18T10:43:15.879680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Read the data\n",
    "\n",
    "We start by reading in the merged flight delay and weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.128993,
     "end_time": "2020-11-18T10:43:16.065704",
     "exception": false,
     "start_time": "2020-11-18T10:43:15.936711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "flight_path = 'data/jfk_flight_weather_features.csv'\n",
    "flight_data = pd.read_csv(flight_path, parse_dates=['flight_date'])\n",
    "flight_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.054146,
     "end_time": "2020-11-18T10:43:16.154043",
     "exception": false,
     "start_time": "2020-11-18T10:43:16.099897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "flight_data['dest'].value_counts().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.097234,
     "end_time": "2020-11-18T10:43:16.283027",
     "exception": false,
     "start_time": "2020-11-18T10:43:16.185793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "flight_data['dest'].value_counts().tail(10)\n",
    "dest_to_drop = ['MKE', 'HYA', 'ALB', 'PSP', 'BDL', 'TUS', 'DAB', 'BHM']\n",
    "flight_data[flight_data['dest'].isin(dest_to_drop)]\n",
    "flight_data.drop(flight_data[flight_data['dest'].isin(dest_to_drop)].index, inplace=True)\n",
    "flight_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039101,
     "end_time": "2020-11-18T10:43:16.360160",
     "exception": false,
     "start_time": "2020-11-18T10:43:16.321059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create train / test data split\n",
    "\n",
    "The first step in building our models is to split the dataset into training and test sets. We use a portion of the data for training, and another portion of data for our test sets.\n",
    "\n",
    "If we instead trained a model on the full dataset, the model would learn to be very good at making predictions on that particular dataset, essentially just copying the answers it knows. However, when presented with data the model has not seen , it would perform poorly since it has not learned how to generalize its answers.\n",
    "\n",
    "By training on a portion of the dataset and testing the model's performance on another portion of the dataset (which data the model has not seen in training), we try to avoid our models \"over-fitting\" the dataset and make them better at prediction when given unseen, future data. This process of splitting the dataset and evaluating a model's performance on \"held-out\" datasets is commonly known as _cross-validation_.\n",
    "\n",
    "By default here we use 80% of the data for the training set and 20% for the test set.\n",
    "\n",
    "**Note** for simplicity here we perform a random split. Technically, we have some time-dependent information leakage, since for earlier records, the model can use data from the future in training. In reality, a model at that point in time would not have information about the future available for training. For a better evaluation of the model performance on fully unseen, new data, the test set should be generated from _future_ data occurring after the time window in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.448639,
     "end_time": "2020-11-18T10:43:16.841145",
     "exception": false,
     "start_time": "2020-11-18T10:43:16.392506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into 80% training and 20% test sets, stratified by the 'delayed' field\n",
    "df_train, df_test = train_test_split(\n",
    "    flight_data, train_size=0.8, random_state=24, stratify=flight_data[['delayed']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.034849,
     "end_time": "2020-11-18T10:43:16.901670",
     "exception": false,
     "start_time": "2020-11-18T10:43:16.866821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify the target variable\n",
    "y_train = df_train['delayed'].values\n",
    "y_test = df_test['delayed'].values\n",
    "print('Training set: {} rows'.format(len(df_train)))\n",
    "print('Test set: {} rows'.format(len(df_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025412,
     "end_time": "2020-11-18T10:43:16.950294",
     "exception": false,
     "start_time": "2020-11-18T10:43:16.924882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Encode categorical variables\n",
    "\n",
    "Next, we want to encode the various _categorical_ features we have - such as the flight departure time bucket, airline and airport ids, and so on - into numerical representations. We do this by assigning integer ids to each unique feature value. This is known as ordinal encoding.\n",
    "\n",
    "Note that certain models (e.g. linear models) will interpret these numerical values as having an ordinal structure. However, for our demonstration purposes we will use tree-based models, which can handle these types of integer ids directly. \n",
    "\n",
    "For linear models, we would prefer to use one-hot encoding for categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.072311,
     "end_time": "2020-11-18T10:43:17.051886",
     "exception": false,
     "start_time": "2020-11-18T10:43:16.979575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# specify columns for raw categorical features\n",
    "cat_columns = [\n",
    "    'month',\n",
    "    'day_of_month',\n",
    "    'day_of_week',\n",
    "    'airline_name',\n",
    "    'dest',\n",
    "    'dep_time_bin',\n",
    "    'distance_bin'\n",
    "]\n",
    "\n",
    "# extract categorical data columns for training set\n",
    "df_train_cat = df_train[cat_columns]\n",
    "# extract categorical data columns for test set\n",
    "df_test_cat = df_test[cat_columns]\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "# fit and encode training features\n",
    "X_train_cat = ord_enc.fit_transform(df_train_cat)\n",
    "# encode test features\n",
    "X_test_cat = ord_enc.transform(df_test_cat)\n",
    "\n",
    "print('Training set categorical features: {} rows, {} features' .format(X_train_cat.shape[0], X_train_cat.shape[1]))\n",
    "print('Test set categorical features: {} rows, {} features' .format(X_test_cat.shape[0], X_test_cat.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044356,
     "end_time": "2020-11-18T10:43:17.144311",
     "exception": false,
     "start_time": "2020-11-18T10:43:17.099955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Encode numerical variables\n",
    "\n",
    "The next step is to encode numerical features. Depending on the models used, it can be very important to scale / normalize numerical features - such as `wind_speed` or `precip`. Again, linear models and neural networks are a good example of this. In our case we will use tree-based models, which again do not require feature scaling, hence we can use these numerical features directly without pre-processing. \n",
    "\n",
    "**Note** that the weather type features are also categorical. However, we have already encoded these as binary values in our pre-processing step, hence we can now treat these features as numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.048752,
     "end_time": "2020-11-18T10:43:17.225546",
     "exception": false,
     "start_time": "2020-11-18T10:43:17.176794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_columns = [\n",
    "    'visibility',\n",
    "    'wind_speed',\n",
    "    'wind_gust_speed',\n",
    "    'precip',\n",
    "    'rain',\n",
    "    'ice_pellets',\n",
    "    'mist',\n",
    "    'snow',\n",
    "    'drizzle',\n",
    "    'haze',\n",
    "    'fog',\n",
    "    'thunderstorm',\n",
    "    'smoke',\n",
    "    'unknown_precipitation'\n",
    "]\n",
    "\n",
    "# extract numerical data columns for training set\n",
    "X_train_num = df_train[num_columns].values\n",
    "# extract numerical data columns for validation set\n",
    "X_test_num = df_test[num_columns].values\n",
    "\n",
    "print('Training set numerical features: {} rows, {} features' .format(X_train_num.shape[0], X_train_num.shape[1]))\n",
    "print('Test set numerical features: {} rows, {} features' .format(X_test_num.shape[0], X_test_num.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.098643,
     "end_time": "2020-11-18T10:43:17.377832",
     "exception": false,
     "start_time": "2020-11-18T10:43:17.279189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Combine categorical and numerical features\n",
    "\n",
    "We can now combine the two sets of features by concatenating them (\"horizontally stacking\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.04915,
     "end_time": "2020-11-18T10:43:17.480635",
     "exception": false,
     "start_time": "2020-11-18T10:43:17.431485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = np.hstack((X_train_cat, X_train_num))\n",
    "X_test = np.hstack((X_test_cat, X_test_num))\n",
    "print('Training set all features: {} rows, {} features' .format(X_train.shape[0], X_train.shape[1]))\n",
    "print('Test set all features: {} rows, {} features' .format(X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026992,
     "end_time": "2020-11-18T10:43:17.537965",
     "exception": false,
     "start_time": "2020-11-18T10:43:17.510973",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train and evaluate models\n",
    "\n",
    "Now that we have pre-processed all our features into numerical representations, we can pass them to our machine learning models.\n",
    "\n",
    "For simplicity, we will evalute 3 tree-based models: a single decision tree; a random forest and a gradient-boosting tree (both of these are \"ensemble\" models made up of many smaller sub-models, typicaly themselves single decision trees).\n",
    "\n",
    "Tree ensemble models are very flexible and powerful, and typically perform well \"out the box\" in particular on tabular datasets such as we have here. As we have seen, they also require less feature pre-processing and engineering in general than, for example, linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.16584,
     "end_time": "2020-11-18T10:43:17.729971",
     "exception": false,
     "start_time": "2020-11-18T10:43:17.564131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "                 \n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "gb = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044233,
     "end_time": "2020-11-18T10:43:17.806791",
     "exception": false,
     "start_time": "2020-11-18T10:43:17.762558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We have split out dataset into a training and test set. However, the test set itself should never be directly used in model training, but only to perform a final model evaluation. This gives an estimate on how the model might perform in the \"real world\".\n",
    "\n",
    "We would still like to perform model selection, which means we need to evaluate our models using the training set in some way. To avoid over-fitting on the training set, as well as to give a good estimate on how the model may perform on our test set, we will use K-fold cross-validation on our training set.\n",
    "\n",
    "This splits the dataset into `k` (in our case `5`) non-overlapping subsets (`folds`). In turn, the model is trained on 4 of these (80% of training data) and evaluated on 1 (20% of training data). This is repeated `k` times and the evaluation scores are averaged across each of the `k` runs. This averaged metric typically gives a fairly good indication of how the model performs on unseen data.\n",
    "\n",
    "`scikit-learn` provides us this functionality, built-in and easy to use!\n",
    "\n",
    "**Note** As we see in the analysis notebook, we are dealing with some degree of class imbalance - on-time flights are far more prevelant compared to delayed flights (80% / 20% split). So, we need to be cautious when evaluting the performance of such models. For example, if we use `accuracy` as a metric, then a simple rule that classifies all flights as `on-time` would achieve 80% accuracy, which sounds very good! However, the model is completely unable to actually predict whether a flight will be delayed, so is useless for any real-world application.\n",
    "\n",
    "A common metric used for binary classification is the area under the ROC curve (`roc_auc`). However, this metric can sometimes provide an unclear picture for imbalanced classes.\n",
    "\n",
    "There are a few metrics that try to alleviate this problem for binary classification problems. We will be using `F1 score` as our metric for selecting the model to use, since it can handle the class imbalance problem. _Note_ that the selection of metric also depends on the particular use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 8.689184,
     "end_time": "2020-11-18T10:43:26.538189",
     "exception": false,
     "start_time": "2020-11-18T10:43:17.849005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric = 'f1'\n",
    "scores = cross_val_score(dt, X_train, y_train, cv=5, scoring=metric)\n",
    "dt_score = np.mean(scores)\n",
    "\n",
    "scores = cross_val_score(rf, X_train, y_train, cv=5, scoring=metric)\n",
    "rf_score = np.mean(scores)\n",
    "\n",
    "scores = cross_val_score(gb, X_train, y_train, cv=5, scoring=metric)\n",
    "gb_score = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.286596,
     "end_time": "2020-11-18T10:43:26.858782",
     "exception": false,
     "start_time": "2020-11-18T10:43:26.572186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_scores = [dt_score, rf_score, gb_score]\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.barplot(x=['DecisionTreeClassifier', 'RandomForestClassifier', 'GradientBoostingClassifier'], y=cv_scores)\n",
    "plt.show()\n",
    "\n",
    "print('Average {} for DecisionTreeClassifier: {}'.format(metric, dt_score))\n",
    "print('Average {} for RandomForestClassifier: {}'.format(metric, rf_score))\n",
    "print('Average {} for GradientBoostingClassifier: {}'.format(metric, gb_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050985,
     "end_time": "2020-11-18T10:43:26.952118",
     "exception": false,
     "start_time": "2020-11-18T10:43:26.901133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Based on this, we will select the `DecisionTreeClassifier`.\n",
    "\n",
    "**Note** based on the `auc_roc` metric, we would have selected the `GradientBoostingClassifier` - try it out in the cells above to see and then compare the model performance later on.\n",
    "\n",
    "We can also evaluate the impact of adding our weather features on model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.490133,
     "end_time": "2020-11-18T10:43:27.499197",
     "exception": false,
     "start_time": "2020-11-18T10:43:27.009064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(dt, X_train_cat, y_train, cv=5, scoring=metric)\n",
    "cat_score = np.mean(scores)\n",
    "\n",
    "scores = cross_val_score(dt, X_train_num, y_train, cv=5, scoring=metric)\n",
    "num_score = np.mean(scores)\n",
    "\n",
    "scores = cross_val_score(dt, X_train, y_train, cv=5, scoring=metric)\n",
    "all_score = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.270508,
     "end_time": "2020-11-18T10:43:27.797814",
     "exception": false,
     "start_time": "2020-11-18T10:43:27.527306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_scores = [cat_score, num_score, all_score]\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.barplot(x=['Flight features', 'Weather features', 'Flight + Weather features'], y=cv_scores)\n",
    "plt.show()\n",
    "\n",
    "print('Average {} for only flight delay features: {}'.format(metric, cat_score))\n",
    "print('Average {} for only weather features: {}'.format(metric, num_score))\n",
    "print('Average {} for all features: {}'.format(metric, all_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03945,
     "end_time": "2020-11-18T10:43:27.867100",
     "exception": false,
     "start_time": "2020-11-18T10:43:27.827650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We see that using only weather features does little better than random guessing, while adding weather features to the flight features increases our metric by around `0.01`. This is not a very large amount, but it does indicate that information about weather helps a little with predictions. In some applications, even small increases in model performance can be significant.\n",
    "\n",
    "Finally, we re-train the model on the full training dataset and perform a final classification evaluation on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.091014,
     "end_time": "2020-11-18T10:43:27.992675",
     "exception": false,
     "start_time": "2020-11-18T10:43:27.901661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score, classification_report\n",
    "from sklearn.metrics import plot_roc_curve, plot_confusion_matrix, plot_precision_recall_curve\n",
    "\n",
    "# fit on full data\n",
    "dt.fit(X_train, y_train)\n",
    "y_prob = dt.predict_proba(X_test)[:, 1]\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "f1_test = f1_score(y_test, y_prob)\n",
    "roc_auc_test = roc_auc_score(y_test, y_prob)\n",
    "print('Final {} for test set: {}'.format(metric, f1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044603,
     "end_time": "2020-11-18T10:43:28.076712",
     "exception": false,
     "start_time": "2020-11-18T10:43:28.032109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We export the trained model and a few example rows from the test dataset, for potential use by downstream stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.048674,
     "end_time": "2020-11-18T10:43:28.166514",
     "exception": false,
     "start_time": "2020-11-18T10:43:28.117840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the model file for downstream tasks\n",
    "from joblib import dump\n",
    "dump(dt, '{}/model.joblib'.format(MODEL_EXPORT_FOLDER))\n",
    "\n",
    "# also save a few example rows\n",
    "np.save('data/test_rows.npy', X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.054397,
     "end_time": "2020-11-18T10:43:28.262088",
     "exception": false,
     "start_time": "2020-11-18T10:43:28.207691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export metrics for KFP\n",
    "metrics = {\n",
    "    'metrics': [\n",
    "        {\n",
    "            'name': 'f1_score',\n",
    "            'numberValue':  f1_test,\n",
    "            'format': 'RAW'\n",
    "        },\n",
    "        {\n",
    "            'name': 'roc_auc_score',\n",
    "            'numberValue':  roc_auc_test,\n",
    "            'format': 'RAW'       \n",
    "        }\n",
    "    ]\n",
    "  }\n",
    "\n",
    "with open('mlpipeline-metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.503831,
     "end_time": "2020-11-18T10:43:28.793550",
     "exception": false,
     "start_time": "2020-11-18T10:43:28.289719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 6))\n",
    "plt.subplot(121)\n",
    "plot_roc_curve(dt, X_test, y_test, ax=fig.gca())\n",
    "plt.subplot(122)\n",
    "plot_precision_recall_curve(dt, X_test, y_test, ax=fig.gca())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.047271,
     "end_time": "2020-11-18T10:43:28.871750",
     "exception": false,
     "start_time": "2020-11-18T10:43:28.824479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['On-time', 'Delayed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.426407,
     "end_time": "2020-11-18T10:43:29.332485",
     "exception": false,
     "start_time": "2020-11-18T10:43:28.906078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_labels = ['On-time', 'Delayed']\n",
    "labels = ['{0:0.0f}'.format(value) for value in\n",
    "                cm.flatten()]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "chart = sns.heatmap(\n",
    "    cm, annot=labels, fmt='', cmap='Blues',\n",
    "    xticklabels=class_labels, yticklabels=class_labels)\n",
    "chart.set_xlabel('Predicted label')\n",
    "chart.set_ylabel('True label')\n",
    "chart.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.094854,
     "end_time": "2020-11-18T10:43:29.491225",
     "exception": false,
     "start_time": "2020-11-18T10:43:29.396371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export confusion matrix for KFP\n",
    "cm_data = []\n",
    "for target_index, target_row in enumerate(cm):\n",
    "    for predicted_index, count in enumerate(target_row):\n",
    "        cm_data.append((class_labels[target_index], class_labels[predicted_index], count))\n",
    "        \n",
    "ui_metadata = {\n",
    "    'outputs' : [{\n",
    "        'type': 'confusion_matrix',\n",
    "        'format': 'csv',\n",
    "        'schema': [\n",
    "            {'name': 'target', 'type': 'CATEGORY'},\n",
    "            {'name': 'predicted', 'type': 'CATEGORY'},\n",
    "            {'name': 'count', 'type': 'NUMBER'},\n",
    "        ],\n",
    "        'source': pd.DataFrame(cm_data).to_csv(header=False, index=False),\n",
    "        'storage': 'inline',\n",
    "        'labels': ['Delayed', 'On-time'],\n",
    "    }]\n",
    "}\n",
    "\n",
    "with open('mlpipeline-ui-metadata.json', 'w') as f:\n",
    "    json.dump(ui_metadata, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.077766,
     "end_time": "2020-11-18T10:43:29.636822",
     "exception": false,
     "start_time": "2020-11-18T10:43:29.559056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If we investigate the various classification charts and reports, we can see that our problem of classifying whether a flight will be delayed is a tricky one.\n",
    "\n",
    "As one might expect, the model predicts most `on-time` flights as `on-time` (80%). However, it struggles to correctly predict `delayed` flights, instead classifying them as `on-time`. In fact it only correctly predicts delays 28% of the time! (this is the `recall` figure for `Delayed` in the classification report table). When it predicts a delayed flight, it is correct only 25% of the time (this is the `precision` field).\n",
    "\n",
    "Overall, we would say that our model is doing a mediocre job of predicting flight delays - we either need to do a lot more model tuning and hyper-parameter selection, or use more data and better features.\n",
    "\n",
    "Perhaps you can try to find ways to improve the performance!\n",
    "\n",
    "Finally, we can generate a list of \"feature importances\" to see what the model is focusing on for making predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.679681,
     "end_time": "2020-11-18T10:43:30.395646",
     "exception": false,
     "start_time": "2020-11-18T10:43:29.715965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat_names = list(df_train_cat.columns.values) + list(df_train[num_columns].columns.values)\n",
    "feat_nb = dt.feature_importances_\n",
    "plt.figure(figsize=(16, 8))\n",
    "chart = sns.barplot(x=feat_names, y=feat_nb, palette='Blues')\n",
    "chart.set_xticklabels(\n",
    "    chart.get_xticklabels(), \n",
    "    rotation=45, \n",
    "    horizontalalignment='right',\n",
    "    fontweight='light',\n",
    "    fontsize='large'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046187,
     "end_time": "2020-11-18T10:43:30.490059",
     "exception": false,
     "start_time": "2020-11-18T10:43:30.443872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Of the flight features, the time-based features as well as departure time and destination seem to be most important. For weather features, wind speed and visibility seem to be dominant in importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.048653,
     "end_time": "2020-11-18T10:43:30.584400",
     "exception": false,
     "start_time": "2020-11-18T10:43:30.535747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Authors\n",
    "This notebook was created by the [Center for Open-Source Data & AI Technologies](http://codait.org).\n",
    "\n",
    "Copyright © 2019 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "duration": 22.125901,
   "end_time": "2020-11-18T10:43:31.907543",
   "environment_variables": {},
   "exception": null,
   "input_path": "/Users/nick/workspace/python/flight-delay-notebooks/notebooks/predict_flight_delays.ipynb",
   "output_path": "/Users/nick/workspace/python/flight-delay-notebooks/notebooks/predict_flight_delays.ipynb",
   "parameters": {},
   "start_time": "2020-11-18T10:43:09.781642",
   "version": "2.1.1"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
